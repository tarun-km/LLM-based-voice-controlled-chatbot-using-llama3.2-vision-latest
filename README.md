# Local LLM-Based Voice Chatbot  

An **AI-powered voice assistant** using **LLaMA 3.2 Vision, Python & Ollama**, running locally on an **RTX 4060 Ti GPU** for real-time, **private AI conversations**.  

## 🔍 Features  
🎙️ **STT & TTS** – Converts speech to text & responds naturally  
👁️ **Vision-Based Responses** – Analyzes images for enhanced interaction  
⚡ **Low-Latency Performance** – Runs efficiently without cloud reliance  

## 🌟 Key Benefits  
✔ **Privacy-Focused** – No cloud dependencies, full local control  
✔ **Real-Time AI Chat** – Fast, responsive, and interactive  
✔ **Optimized for GPUs** – Leverages RTX 4060 Ti for seamless AI processing  

## ⚠️ Limitations  
❌ **Hardware Dependent** – Requires a powerful GPU for smooth operation  
❌ **Limited Remote Access** – Runs locally, no cloud integration  
❌ **Setup Complexity** – Initial configuration may require technical expertise  

_🚀 Experience real-time, private AI conversations with a local voice chatbot!_  
